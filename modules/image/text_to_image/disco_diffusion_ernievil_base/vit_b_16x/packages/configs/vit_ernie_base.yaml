# The frequency to save trained models when training.
save_step: 500
# The frequency to fetch and print output when training.
print_step: 10

# The directory for saving model
save_model: "checkpoints"
# The directory for saving inference model
inference_model_dir: "infer_model"
# Set seed for CE or debug
random_seed: 1024

# The data type of input ids.
input_dtype: "int64"

# Device to use.
device: "gpu"

# TODO fix
#batch_size: 2000
batch_size: 100

infer_batch_size: 1500
shuffle_batch: False
# Data shuffle only works when sort_type is pool or none
shuffle: False
# shuffle_seed must be set when shuffle is True and using multi-cards to train.
# Otherwise, the number of batches cannot be guaranteed.
shuffle_seed: 128

# The number of epoches for training
epoch: 50


#learning_rate: 0.00005
learning_rate: 0.00003


beta1: 0.9
beta2: 0.997
eps: 1e-9
# The parameters for learning rate scheduling.
warmup_steps: 1000

# Dropout rates.
dropout: 0.1


# Mixed precision training
use_amp: True
use_pure_fp16: False
scale_loss: 128.0

# Maximum iteration for training.
max_iter: None

do_train: True

max_text_seqlen: 48
vocab_file: "./packages/ernie_base_3.0/vocab.txt"
text_model_config: "./packages/ernie_base_3.0/ernie_config.base.json"

pad_token: 0
cls_token: 1
sep_token: 2
mask_token: 3
unk_token: 17963
